\section{Natural Language Processing Methodology}
\label{sec:nlp_methodology}

Building on the established causal impact, we now turn to our primary contribution: a comprehensive NLP analysis of how question content, complexity, and focus have evolved in response to ChatGPT's introduction. This section outlines our NLP methodology for detecting and characterizing these changes.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Data Pre-processing}
\textit{[PREPROCESSING PLACEHOLDER - Will detail specific preprocessing steps including tokenization, stopword removal, lemmatization, etc.]}

The resulting word clouds show no immediate clear trend:

\begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{imgs/wordclouds/wc_stackoverflow_pre_alphanum.png}
        \caption{Pre-treatment wordcloud}
        \label{fig:prewc}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.475\textwidth}
        \centering
        \includegraphics[width=1\linewidth]{imgs/wordclouds/wc_stackoverflow_post_alphanum.png}
        \caption{Post-treatment wordcloud}
        \label{fig:postwc}
    \end{subfigure}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Topic Modeling}
\textit{[TOPIC MODELING PLACEHOLDER - Will describe topic modeling approach (e.g., LDA), parameter selection, and validation strategies]}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Complexity Analysis}

We construct a parsimonious complexity score for forum posts which is composed of 4 key elements: (1) title length, (2) body length, (3) number of tags and (4) length of technical expressions (i.e. code, or equation length for the respective forums).\footnote{We used different metrics appropriate to each forum's content: code length was measured for Stack Overflow, Superuser, and Askubuntu, while equation length was used for Mathematics and Physics. This distinction reflects the content patterns in our data, as Physics and Mathematics questions contained code in fewer than 5\% of posts, while the technology-focused forums rarely contained equations.} The reason for choosing this relatively simple score is that questions often use snippets of code or equations. Thus, more sophisticated and established equation or code complexity algorithms become unusable. The results are interesting anyway:

\begin{multline}\label{eq:cscore}
    \text{Treatment: Complexity Score}_i = \\
    \frac{1}{4} \left( \frac{\text{AvgTags}_i - \mu_{\text{AvgTags}}}{\sigma_{\text{AvgTags}}} + \frac{\text{AvgTechExprLength}_i - \mu_{\text{AvgTechExprLength}}}{\sigma_{\text{AvgTechExprLength}}} \right. \\
    \left. + \frac{\text{AvgBodyLength}_i - \mu_{\text{AvgBodyLength}}}{\sigma_{\text{AvgBodyLength}}} + \frac{\text{AvgTitleLength}_i - \mu_{\text{AvgTitleLength}}}{\sigma_{\text{AvgTitleLength}}} \right)
\end{multline}

\begin{figure}[H]
    \centering
    \includesvg[width=1\linewidth]{imgs/stackoverflow_vs_rest.svg}
    \caption{Treatment vs. Control: Question complexity over time}
    \label{fig:complex}
\end{figure}


